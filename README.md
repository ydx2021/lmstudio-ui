# lmstudio-ui
One page Web UI for LM Studio, Ollama and compatitle LLM servers. 
Usage: Just open the lmstudio-ui.html file with a browser, or run 
"python -m http.server 8080" to serve it from localhost:8080


IMPORTANT: you must enable CORS on LM Studio for it to work. 
